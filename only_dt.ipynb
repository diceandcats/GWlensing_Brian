{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from math import ceil, floor\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "from lenstronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.LensModel.Solver.lens_equation_solver import LensEquationSolver\n",
    "from cluster_local import ClusterLensing_fyp\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the first datax array: 799\n"
     ]
    }
   ],
   "source": [
    "# inject data\n",
    "\n",
    "scenarios = {\n",
    "    '1': 'abell370',\n",
    "    '2': 'abell2744',\n",
    "    '3': 'abells1063',\n",
    "    '4': 'macs0416',\n",
    "    '5': 'macs0717',\n",
    "    '6': 'macs1149'\n",
    "}\n",
    "\n",
    "full_cluster_names = {\n",
    "    'abell370': 'Abell 370',\n",
    "    'abell2744': 'Abell 2744',\n",
    "    'abells1063': 'Abell S1063',\n",
    "    'macs0416': 'MACS J0416.1-2403',\n",
    "    'macs0717': 'MACS J0717.5+3745',\n",
    "    'macs1149': 'MACS J1149.5+2223'\n",
    "}\n",
    "\n",
    "# Initialize lists to store the data arrays\n",
    "datax_list = []\n",
    "datay_list = []\n",
    "data_psi_list = []\n",
    "\n",
    "for i in scenarios:\n",
    "    clustername = scenarios[i]\n",
    "    full_cluster_name = full_cluster_names[clustername]\n",
    "\n",
    "    file_dir = os.getcwd()\n",
    "    fits_filex = os.path.join(\n",
    "        file_dir,\n",
    "        f'GCdata/{full_cluster_name}/hlsp_frontier_model_{clustername}_williams_v4_x-arcsec-deflect.fits'\n",
    "    )\n",
    "    fits_filey = os.path.join(\n",
    "        file_dir,\n",
    "        f'GCdata/{full_cluster_name}/hlsp_frontier_model_{clustername}_williams_v4_y-arcsec-deflect.fits'\n",
    "    )\n",
    "    psi_file = os.path.join(\n",
    "        file_dir,\n",
    "        f'GCdata/{full_cluster_name}/hlsp_frontier_model_{clustername}_williams_v4_psi.fits'\n",
    "    )\n",
    "\n",
    "    with fits.open(fits_filex) as hdulx, fits.open(fits_filey) as hduly, fits.open(psi_file) as hdul_psi:\n",
    "        datax = hdulx[0].data\n",
    "        datay = hduly[0].data\n",
    "        data_psi = hdul_psi[0].data\n",
    "\n",
    "        # Append the data arrays to the lists\n",
    "        datax_list.append(datax)\n",
    "        datay_list.append(datay)\n",
    "        data_psi_list.append(data_psi)\n",
    "\n",
    "# Example: Access the first datax array\n",
    "print(f\"Length of the first datax array: {len(datax_list[2])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.25, 0.25, 0.2, 0.2, 0.2]\n"
     ]
    }
   ],
   "source": [
    "# getting the pixel scale list\n",
    "def get_pixscale(cluster_name, file_path='GCdata/pixsize'):\n",
    "    full_path = os.path.join(file_dir, file_path)\n",
    "    with open(full_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(cluster_name):\n",
    "                # Split the line to get the value after the colon and return it as a float\n",
    "                return float(line.split(':')[1].strip())\n",
    "    return None  # Return None if the cluster name isn't found\n",
    "\n",
    "pixscale_list = []\n",
    "for i in scenarios:\n",
    "    clustername = scenarios[i]\n",
    "    full_cluster_name = full_cluster_names[clustername]\n",
    "    pixscale = get_pixscale(full_cluster_name)\n",
    "    pixscale_list.append(pixscale)\n",
    "print(pixscale_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the class\n",
    "cluster = ClusterLensing_fyp(datax_list, datay_list, data_psi_list, 0.5, 1, pixscale_list, diff_z=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n"
     ]
    }
   ],
   "source": [
    "print(len(datax_list[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([106.51129008,  54.373867  ,  94.50298699,  65.15280208,\n",
      "        83.72098886]), array([37.60187869, 97.69887162, 88.69469174, 59.78233641, 73.23005261]))\n",
      "[ 1.74328197  1.63793269 -1.9422805  -5.59530548  0.62218531]\n",
      "[0.0, 32320.47736167349, 59054.80822375999, 64898.43362806528, 67900.2558774827]\n"
     ]
    }
   ],
   "source": [
    "# check with the lenstronomy package directly\n",
    "realsize = 698\n",
    "grid = np.linspace(0, realsize-1, realsize)\n",
    "grid = grid * 0.2\n",
    "\n",
    "lens_model_list2 = ['INTERPOL']\n",
    "kwargs_lens2 = [{'grid_interp_x': grid, 'grid_interp_y': grid, 'f_': data_psi_list[5]*0.2**2,\n",
    "                          'f_x': datax_list[5], 'f_y': datay_list[5]}]\n",
    "\n",
    "lensModel_real = LensModel(lens_model_list=lens_model_list2, z_source=1, z_lens=0.5)\n",
    "\n",
    "# Use lens equation solver for verification\n",
    "solver2 = LensEquationSolver(lensModel_real)\n",
    "coord = (76.70065971846965, 64.7852180985455)\n",
    "img_po = solver2.image_position_from_source(coord[0], coord[1], kwargs_lens2, min_distance=0.2, search_window=100, verbose=False, x_center=70, y_center=65)\n",
    "print(img_po)\n",
    "mag = lensModel_real.magnification(img_po[0], img_po[1], kwargs_lens2)\n",
    "print(mag)\n",
    "dt = lensModel_real.arrival_time(img_po[0], img_po[1], kwargs_lens2)\n",
    "dt = [dt_ - dt[0] for dt_ in dt]\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt and mag data\n",
    "\n",
    "mag = (1.49972905, 7.42332916, -11.5028191, -4.07344553, -3.28229147, 3.14782126, 3.57746724)\n",
    "dt =[0.0, 3464.586642261129, 24012.56500505423, 25331.258614414837, 25887.914411486126]\n",
    "dt_ref = [0.0, 88594.90558064939, 91797.85200701188, 91896.81383935199, 92121.65322824288, 92551.52745506703, 93534.55033071572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "src_guess = (81,71.3)\n",
    "chi_sq = cluster.chi_squared(src_guess, dt, index = 0)\n",
    "print(chi_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# localization of source position given the index of cluster\n",
    "x_approx, y_approx, chi_sq = cluster.localize_known_cluster_diffevo(dt_true = dt, index = 1)\n",
    "print(x_approx, y_approx, chi_sq)\n",
    "print((x_approx-src_guess[0])**2 + (y_approx-src_guess[1])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [81.00000038017119, 71.29999998618307] 2.1059426626038668e-05\n"
     ]
    }
   ],
   "source": [
    "# localization of source position with unknown cluster\n",
    "index, src_pos, chi_sq , src_guess, chi_sqs= cluster.localize_diffevo(dt_true = dt)\n",
    "print(index, src_pos, chi_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding source 0\n"
     ]
    }
   ],
   "source": [
    "# localization of source position with unknown cluster for multiple sources\n",
    "src = pd.read_csv('src_pos_for_distribution.csv')\n",
    "src_pos_test,index_test = src[['x', 'y']].values, src['indices'].values\n",
    "\n",
    "for i in range(len(index_test)):\n",
    "    img = cluster.image_position(src_pos_test[i][0], src_pos_test[i][1], index_test[i])\n",
    "    dt = cluster.time_delay(img[0], img[1], index_test[i])\n",
    "    print(f'Finding source {i}')\n",
    "    index, src_pos, chi_sq , _, _ = cluster.localize_diffevo(dt_true=dt)\n",
    "    src.at[i, 'localized_index'] = index\n",
    "    src.at[i, 'localized_x'] = src_pos[0]\n",
    "    src.at[i, 'localized_y'] = src_pos[1]\n",
    "    src.at[i, 'localized_chi_sq'] = chi_sq\n",
    "    src.to_csv('src_pos_for_distribution.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
